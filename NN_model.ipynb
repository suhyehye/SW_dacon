{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wagar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv',index_col=0)\n",
    "test_data = pd.read_csv('test.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 명목형 변수 변환\n",
    "replace_dict = {'education':str, 'engnat':str, 'married':str, 'urban':str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#familysize >50 제거\n",
    "train_data = train_data.drop(train_data[train_data.familysize > 50].index)\n",
    "\n",
    "#불필요하다고 판단되는 변수 제거\n",
    "train_data = train_data.drop(columns=['country','introelapse','testelapse','surveyelapse','hand'])\n",
    "test_data = test_data.drop(columns=['country','introelapse','testelapse','surveyelapse','hand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(columns=['nerdiness'])\n",
    "y_train = train_data['nerdiness']\n",
    "X_test = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 명목형 변수로 변환\n",
    "X_train = X_train.astype(replace_dict)\n",
    "X_test = X_test.astype(replace_dict)\n",
    "\n",
    "# 더미 변수 변한\n",
    "X_train = pd.get_dummies(X_train).to_numpy()\n",
    "X_test = pd.get_dummies(X_test).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32)\n",
    "x_test_t = torch.tensor(X_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14999, 75]) torch.Size([14999])\n"
     ]
    }
   ],
   "source": [
    "print(X_train_t.shape, y_train_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35452, 75])\n"
     ]
    }
   ],
   "source": [
    "print(x_test_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_len = len(x_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_REPEAT = 5\n",
    "N_SKFOLD = 7\n",
    "N_EPOCH = 48\n",
    "BATCH_SIZE = 75\n",
    "LOADER_PARAM = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'num_workers': 4,\n",
    "    'pin_memory': True\n",
    "}\n",
    "prediction = np.zeros((test_len, 1), dtype=np.float32)\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/07: 100%|██████████| 48/48 [04:22<00:00,  5.47s/it]\n",
      "02/07: 100%|██████████| 48/48 [04:50<00:00,  6.06s/it]\n",
      "03/07: 100%|██████████| 48/48 [04:51<00:00,  6.08s/it]\n",
      "04/07: 100%|██████████| 48/48 [04:47<00:00,  6.00s/it]\n",
      "05/07: 100%|██████████| 48/48 [04:38<00:00,  5.81s/it]\n",
      "06/07: 100%|██████████| 48/48 [04:29<00:00,  5.61s/it]\n",
      "07/07: 100%|██████████| 48/48 [04:28<00:00,  5.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R1 -> 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/07: 100%|██████████| 48/48 [04:54<00:00,  6.14s/it]\n",
      "02/07: 100%|██████████| 48/48 [04:50<00:00,  6.06s/it]\n",
      "03/07: 100%|██████████| 48/48 [04:59<00:00,  6.23s/it]\n",
      "04/07: 100%|██████████| 48/48 [04:50<00:00,  6.05s/it]\n",
      "05/07: 100%|██████████| 48/48 [04:48<00:00,  6.02s/it]\n",
      "06/07: 100%|██████████| 48/48 [04:55<00:00,  6.16s/it]\n",
      "07/07: 100%|██████████| 48/48 [04:43<00:00,  5.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 -> 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/07: 100%|██████████| 48/48 [05:00<00:00,  6.26s/it]\n",
      "02/07: 100%|██████████| 48/48 [05:03<00:00,  6.32s/it]\n",
      "03/07: 100%|██████████| 48/48 [04:47<00:00,  6.00s/it]\n",
      "04/07: 100%|██████████| 48/48 [04:19<00:00,  5.40s/it]\n",
      "05/07: 100%|██████████| 48/48 [04:45<00:00,  5.96s/it]\n",
      "06/07: 100%|██████████| 48/48 [04:41<00:00,  5.86s/it]\n",
      "07/07: 100%|██████████| 48/48 [04:41<00:00,  5.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R3 -> 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/07: 100%|██████████| 48/48 [04:42<00:00,  5.89s/it]\n",
      "02/07: 100%|██████████| 48/48 [04:45<00:00,  5.94s/it]\n",
      "03/07: 100%|██████████| 48/48 [04:57<00:00,  6.20s/it]\n",
      "04/07: 100%|██████████| 48/48 [04:53<00:00,  6.10s/it]\n",
      "05/07: 100%|██████████| 48/48 [04:45<00:00,  5.95s/it]\n",
      "06/07: 100%|██████████| 48/48 [04:51<00:00,  6.08s/it]\n",
      "07/07: 100%|██████████| 48/48 [05:01<00:00,  6.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R4 -> 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/07: 100%|██████████| 48/48 [05:11<00:00,  6.49s/it]\n",
      "02/07: 100%|██████████| 48/48 [05:01<00:00,  6.28s/it]\n",
      "03/07: 100%|██████████| 48/48 [05:01<00:00,  6.28s/it]\n",
      "04/07: 100%|██████████| 48/48 [04:51<00:00,  6.07s/it]\n",
      "05/07: 100%|██████████| 48/48 [04:34<00:00,  5.72s/it]\n",
      "06/07: 100%|██████████| 48/48 [04:28<00:00,  5.60s/it]\n",
      "07/07: 100%|██████████| 48/48 [04:28<00:00,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R5 -> 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for repeat in range(N_REPEAT):\n",
    "\n",
    "    skf, tot = StratifiedKFold(n_splits=N_SKFOLD, random_state=repeat, shuffle=True), 0.\n",
    "    for skfold, (train_idx, valid_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "        train_idx, valid_idx = list(train_idx), list(valid_idx)\n",
    "        train_loader = DataLoader(TensorDataset(X_train_t[train_idx, :], y_train_t[train_idx]),\n",
    "                                  shuffle=True, drop_last=True, **LOADER_PARAM)\n",
    "        valid_loader = DataLoader(TensorDataset(X_train_t[valid_idx, :], y_train_t[valid_idx]),\n",
    "                                  shuffle=False, drop_last=False, **LOADER_PARAM)\n",
    "        test_loader = DataLoader(TensorDataset(x_test_t, torch.zeros((test_len,), dtype=torch.float32)),\n",
    "                                 shuffle=False, drop_last=False, **LOADER_PARAM)\n",
    "        model = nn.Sequential(\n",
    "            nn.Dropout(0.05),\n",
    "            nn.Linear(75, 180, bias=False),\n",
    "            nn.LeakyReLU(0.05, inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(180, 32, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 1)\n",
    "        ).to(DEVICE)\n",
    "        criterion = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([1.20665], device=DEVICE))\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=5e-3, weight_decay=7.8e-2)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer, T_0=N_EPOCH // 6, eta_min=4e-4)\n",
    "        prediction_t, loss_t = np.zeros((test_len, 1), dtype=np.float32), 1.\n",
    "\n",
    "        # for epoch in range(N_EPOCH):\n",
    "        for epoch in tqdm(range(N_EPOCH), desc='{:02d}/{:02d}'.format(skfold + 1, N_SKFOLD)):\n",
    "            model.train()\n",
    "            for idx, (xx, yy) in enumerate(train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                xx, yy = xx.to(DEVICE), yy.to(DEVICE)\n",
    "                pred = model(xx).squeeze()\n",
    "                loss = criterion(pred, yy)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step(epoch + idx / len(train_loader))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                running_acc, running_loss, running_count = 0, 0., 0\n",
    "                for xx, yy in valid_loader:\n",
    "                    xx, yy = xx.to(DEVICE), yy.to(DEVICE)\n",
    "                    pred = model(xx).squeeze()\n",
    "                    loss = criterion(pred, yy)\n",
    "                    running_loss += loss.item() * len(yy)\n",
    "                    running_count += len(yy)\n",
    "                    running_acc += ((torch.sigmoid(pred) > 0.5).float() == yy).sum().item()\n",
    "                # print('R{:02d} S{:02d} E{:02d} | {:6.4f}, {:5.2f}%'\n",
    "                #       .format(repeat + 1, skfold + 1, epoch + 1, running_loss / running_count,\n",
    "                #               running_acc / running_count * 100))\n",
    "\n",
    "                if running_loss / running_count < loss_t:\n",
    "                    loss_t = running_loss / running_count\n",
    "                    for idx, (xx, _) in enumerate(test_loader):\n",
    "                        xx = xx.to(DEVICE)\n",
    "                        pred = (2. - torch.sigmoid(model(xx).detach().to('cpu'))).numpy()\n",
    "                        prediction_t[BATCH_SIZE * idx:min(BATCH_SIZE * (idx + 1), len(prediction)), :] \\\n",
    "                            = pred[:, :].copy()\n",
    "        prediction[:, :] += prediction_t[:, :].copy() / (N_REPEAT * N_SKFOLD)\n",
    "        tot += loss_t\n",
    "    print('R{} -> {:6.4f}'.format(repeat + 1, tot / N_SKFOLD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sample_submission.csv')\n",
    "df.iloc[:, 1:] = prediction\n",
    "df.to_csv('{}.csv'.format(datetime.now().strftime('%m%d-%H%M')), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3bca2543b8101edd63d2d1b99aee8dd9a39c6a97fc4f450cf710205e940bdbfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
